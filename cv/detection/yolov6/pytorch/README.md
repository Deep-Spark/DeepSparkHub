# YOLOv6
## Model description
For years, the YOLO series has been the de facto industry-level standard for efficient object detection. The YOLO community has prospered overwhelmingly to enrich its use in a multitude of hardware platforms and abundant scenarios. In this technical report, we strive to push its limits to the next level, stepping forward with an unwavering mindset for industry application.
Considering the diverse requirements for speed and accuracy in the real environment, we extensively examine the up-to-date object detection advancements either from industry or academia. Specifically, we heavily assimilate ideas from recent network design, training strategies, testing techniques, quantization, and optimization methods. On top of this, we integrate our thoughts and practice to build a suite of deployment-ready networks at various scales to accommodate diversified use cases. With the generous permission of YOLO authors, we name it YOLOv6. We also express our warm welcome to users and contributors for further enhancement. For a glimpse of performance, our YOLOv6-N hits 35.9% AP on the COCO dataset at a throughput of 1234 FPS on an NVIDIA Tesla T4 GPU. YOLOv6-S strikes 43.5% AP at 495 FPS, outperforming other mainstream detectors at the same scale~(YOLOv5-S, YOLOX-S, and PPYOLOE-S). Our quantized version of YOLOv6-S even brings a new state-of-the-art 43.3% AP at 869 FPS. Furthermore, YOLOv6-M/L also achieves better accuracy performance (i.e., 49.5%/52.3%) than other detectors with a similar inference speed. We carefully conducted experiments to validate the effectiveness of each component. 
Implementation of paper:
- [YOLOv6 v3.0: A Full-Scale Reloading](https://arxiv.org/abs/2301.05586) ðŸ”¥
- [YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications](https://arxiv.org/abs/2209.02976)


## Installing packages
```
## install libGL
yum install mesa-libGL

## install zlib
wget http://www.zlib.net/fossils/zlib-1.2.9.tar.gz
tar xvf zlib-1.2.9.tar.gz
cd zlib-1.2.9/
./configure && make install
cd ..
rm -rf zlib-1.2.9.tar.gz zlib-1.2.9/
```

```
pip3 install -r requirements.txt
```

## Preparing datasets
- data: prepare dataset and specify dataset paths in data.yaml ( [COCO](http://cocodataset.org), [YOLO format coco labels](https://github.com/meituan/YOLOv6/releases/download/0.1.0/coco2017labels.zip) )
- make sure your dataset structure as follows:
```
â”œâ”€â”€ coco
â”‚   â”œâ”€â”€ annotations
â”‚   â”‚   â”œâ”€â”€ instances_train2017.json
â”‚   â”‚   â””â”€â”€ instances_val2017.json
â”‚   â”œâ”€â”€ images
â”‚   â”‚   â”œâ”€â”€ train2017
â”‚   â”‚   â””â”€â”€ val2017
â”‚   â”œâ”€â”€ labels
â”‚   â”‚   â”œâ”€â”€ train2017
â”‚   â”‚   â”œâ”€â”€ val2017
â”‚   â”œâ”€â”€ LICENSE
â”‚   â”œâ”€â”€ README.txt
```

## Training

Single gpu train

```
python3 tools/train.py --batch 32 --conf configs/yolov6s.py --data data/coco.yaml --epoch 300 --name yolov6s_coco
```

Multiple gpu train
```
python3 -m torch.distributed.launch --nproc_per_node 8 tools/train.py --batch 256 --conf configs/yolov6s.py --data data/coco.yaml --epoch 300 --name yolov6s_coco --device 0,1,2,3,4,5,6,7
```

## Training Results
Model                                                        | Size | mAP<sup>val<br/>0.5:0.95 | mAP<sup>val<br/>0.5 |
| :----------------------------------------------------------- | ---- | :----------------------- | --------------------------------------- |
| YOLOv6-S| 640  | 44.3                     | 61.3                                     | 

## Remark
After training, reporting "AttributeError: 'NoneType' object has no attribute 'python_exit_status'" is a [known issue](https://github.com/meituan/YOLOv6/issues/506), add "--workers 0" if you want to avoid.

## Reference
https://github.com/meituan/YOLOv6
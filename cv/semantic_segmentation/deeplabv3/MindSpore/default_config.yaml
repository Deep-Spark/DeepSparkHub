# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "Ascend" # ['Ascend', 'CPU']

# ==============================================================================
# Training options
train_dir: "/cache/train/ckpt"

# dataset
need_modelarts_dataset_unzip: True
data_file: ""
batch_size: 32
crop_size: 513
image_mean: [103.53, 116.28, 123.675]
image_std: [57.375, 57.120, 58.395]
min_scale: 0.5
max_scale: 2.0
ignore_label: 255
num_classes: 21

# optimizer
train_epochs: 300
lr_type: "cos"
base_lr: 0.015
lr_decay_step: 40000
lr_decay_rate: 0.1
loss_scale: 3072.0

# model
model: "deeplab_v3_s16"
freeze_bn: False
ckpt_pre_trained: ""
filter_weight: False

# train
is_distributed: False
rank: 0
group_size: 1
save_steps: 3000
keep_checkpoint_max: 1

# eval param
data_root: ""
data_lst: ""
scales: [1.0,]
scales_list: [[1.0,], [0.5, 0.75, 1.0, 1.25, 1.75]]
scales_type: 0
flip: False
ckpt_path: ""
input_format: "NCHW" # ["NCHW", "NHWC"]

# export param
device_id: 0
export_batch_size: 1
input_size: 513
ckpt_file: ""
file_name: "deeplabv3"
file_format: "MINDIR"
export_model: "deeplab_v3_s8"

---

# Help description for each configuration
enable_modelarts: "Whether training on modelarts, default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of the input data."
output_path: "The location of the output file."
device_target: 'Target device type'
train_dir: "where training log and ckpts saved"
data_file: "path and name of one mindrecord file"
batch_size: "batch size"
crop_size: "crop size"
image_mean: "image mean"
image_std: "image std"
min_scale: "minimum scale of data argumentation"
max_scale: "maximum scale of data argumentation"
ignore_label: "ignore label"
num_classes: "number of classes"
train_epochs: "epoch"
lr_type: "type of learning rate"
base_lr: "base learning rate"
lr_decay_step: "learning rate decay step"
lr_decay_rate: "learning rate decay rate"
loss_scale: "loss scale"
model: "select model"
freeze_bn: "freeze bn, need to set to True when run without onnx"
ckpt_pre_trained: "pretrained model"
filter_weight: "Filter the last weight parameters, default is False."
is_distributed: "distributed training"
rank: "local rank of distributed"
group_size: "world size of distributed"
save_steps: "steps interval for saving"
keep_checkpoint_max: "max checkpoint for saving"

data_root: "root path of val data"
data_lst: "list of val data"
scales: "scales of evaluation"
flip: "perform left-right flip"
ckpt_path: "model to evaluat"
input_format: "NCHW or NHWC"

# export param
device_id: "Device id"
export_batch_size: "batch size for export"
input_size: "input_size"
ckpt_file: "Checkpoint file path."
file_name: "output file name."
file_format: "file format, choices in ['AIR', 'MINDIR']"
export_model: "Select model structure (Default: deeplab_v3_s8), choices in ['deeplab_v3_s16', 'deeplab_v3_s8']"